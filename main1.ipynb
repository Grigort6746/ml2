{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройка вывода данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение дата сетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/pj6yt0sd06b04mcq4xjmcl2h0000gn/T/ipykernel_3506/3447217829.py:1: DtypeWarning: Columns (51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,131,132,133,135,136,139,140,141,142,143,144,145,146,147,148,149,151,152,155,156,157,158,159,160,161,163,164,165,167,168,169,171,172,173,174,175,176,177,178,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,223,224,227,239,240,241,242,243,244,245,246,459,460,461,467,468,469,515,516,523,524,531,532,539,540,547,548,555,556,563,564,565,567,571,572,573,575,579,580,581,582,583,587,588,595,596,603,604,611,612,613,615,795,796,797,799,1031,1032,1033,1034,1035,1036,1037,1039,1040,1041,1042,1043,1044,1045,1047,1048,1049,1050,1051,1052,1055,1056,1057,1058,1059,1060,1063,1064,1065,1067,1068,1069,1072,1073,1074,1075,1076,1077,1078,1172,1173,1174,1176,1177,1178,1179,1180,1181,1182,1275,1276,1277,1278,1279,1280,1281,1282,1447,1448,1449,1450,1451,1452,1453,1454,1649,1650,1651,1652,1653,1654,1655,1656,2193,2194,2195,2196,2199) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('train.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df1 = pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление дубликатов и столбцов с более чем 25% пропущенных значений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "threshold = len(df) * 0.75\n",
    "res = df.dropna(thresh=threshold, axis=1)\n",
    "res.to_csv(\"res.csv\", index=False)\n",
    "print(res.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотр количества пропущеных значений по столбцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report_date      0\n",
      "client_id        0\n",
      "target           0\n",
      "col1453          0\n",
      "col1454          1\n",
      "col2167         23\n",
      "col2168         23\n",
      "col2169         23\n",
      "col2170         23\n",
      "col2171         23\n",
      "col2172         23\n",
      "col2173         23\n",
      "col2174         23\n",
      "col2175         23\n",
      "col2176         23\n",
      "col2177         23\n",
      "col2178         23\n",
      "col2179         23\n",
      "col2180         23\n",
      "col2181         23\n",
      "col2182         23\n",
      "col2183         23\n",
      "col2184         23\n",
      "col2185         23\n",
      "col2186         23\n",
      "col2187         23\n",
      "col2188         23\n",
      "col2189         23\n",
      "col2190         23\n",
      "col2220         37\n",
      "col2221         37\n",
      "col2222         37\n",
      "col2244        370\n",
      "col2245        370\n",
      "col2246        370\n",
      "col2292         37\n",
      "col2293         37\n",
      "col2294         37\n",
      "col2316         37\n",
      "col2317         37\n",
      "col2318         37\n",
      "col2340         37\n",
      "col2341         37\n",
      "col2342         37\n",
      "col2364         37\n",
      "col2365         37\n",
      "col2366         37\n",
      "col2388         37\n",
      "col2389         37\n",
      "col2390         37\n",
      "col2460        239\n",
      "col2461        239\n",
      "col2462        239\n",
      "col2470        708\n",
      "col2663          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_value_count = res.isna().sum()\n",
    "print(missing_value_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем категориальные столбцы которые должны закодировать\n",
    "Потом кодируем данные\n",
    "И заполняем оставшиеся пропущенные значения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = res.select_dtypes(include=['object']).columns\n",
    "res_encoded = pd.get_dummies(res, columns=categorical_columns)\n",
    "\n",
    "res_encoded = res_encoded.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем матрицу корреляции, выявляем и удаляем столбцы слишком сильно коррелирующие между собой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = res_encoded.corr()\n",
    "threshold = 0.9\n",
    "high_corr_pairs = [(col1, col2) for col1 in corr_matrix.columns for col2 in corr_matrix.columns if col1 != col2 and abs(corr_matrix.loc[col1, col2]) > threshold]\n",
    "to_drop = [pair[1] for pair in high_corr_pairs]\n",
    "clean = res_encoded.drop(columns=to_drop)\n",
    "clean.to_csv('clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим тепловую карту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Тепловая карта корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем лишние булевые колонки появившиеся в ходе выше указаных преобразований"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'bool':\n",
    "        df = df.drop(columns=column)\n",
    "\n",
    "df.to_csv(\"clean1.csv\", index=False)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим столбцы таблицы valid которых нету в таблице train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid1 = df1.reindex(columns=df.columns)\n",
    "valid1.to_csv(\"valid1.csv\", index=False)\n",
    "valid1 = pd.read_csv('valid1.csv')\n",
    "valid1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка выборок для обучения и тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean1 = pd.read_csv('clean1.csv')\n",
    "valid1 = pd.read_csv('valid1.csv')\n",
    "\n",
    "# разделение на признаки и целевую переменную train\n",
    "X = clean1.drop('target', axis=1)\n",
    "y = clean1['target']\n",
    "\n",
    "# сохранение признаков и целевой переменной train\n",
    "X.to_csv('features.csv', index=False)\n",
    "y.to_csv('target.csv', index=False)\n",
    "\n",
    "\n",
    "# разделение на признаки и целевую переменную valid\n",
    "x_valid = valid1.drop('target', axis=1)\n",
    "y_valid = valid1['target']\n",
    "\n",
    "# сохранение признаков и целевой переменной valid\n",
    "x_valid.to_csv('features_val.csv', index=False)\n",
    "y_valid.to_csv('target_val.csv', index=False)\n",
    "\n",
    "# загрузка данных train\n",
    "X = pd.read_csv('features.csv')\n",
    "y = pd.read_csv('target.csv')\n",
    "\n",
    "# разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# загрузка данных valid\n",
    "X_val = pd.read_csv('features_val.csv')\n",
    "y_val = pd.read_csv('target_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание модели, установка гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(\n",
    "    n_estimators=5,       # количество деревьев\n",
    "    max_depth=5,           # глубина деревьев\n",
    "    min_samples_split=25,  # минимальное количество образцов для разделения\n",
    "    min_samples_leaf=15,    # минимальное количество образцов в листе\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = BaggingRegressor(estimator=base_model, n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание на тестовых данных иполучение метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказание на тестовых данных\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# вычисление ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC-AUC Score: {roc_auc}')\n",
    "\n",
    "# вывод графика ROC-AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# вывод MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE: {mse}\")\n",
    "\n",
    "# вывод RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# вывод графика MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание на валидационных данных и получение метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказание на данных valid\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "\n",
    "# вычисление ROC-AUC\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "print(f'ROC-AUC Score: {roc_auc}')\n",
    "\n",
    "# вывод графика ROC-AUC\n",
    "fpr, tpr, thresholds1 = roc_curve(y_val, y_val_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"MSE: {mse}\")\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "print(f\"MAE: {mae}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
